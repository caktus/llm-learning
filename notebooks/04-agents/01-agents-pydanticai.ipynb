{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5dd06bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7c4cdc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VS Code's Jupyter extension doesn't support loading .envrc, so if you're using VS Code, we load it here.\n",
    "\n",
    "import sys\n",
    "\n",
    "if \"../..\" not in sys.path:\n",
    "    sys.path.insert(0, \"../..\")\n",
    "\n",
    "from notebooks.utils import load_envrc\n",
    "\n",
    "load_envrc(\"../../.envrc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02786606",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import get_console\n",
    "from rich.console import Console\n",
    "\n",
    "console: Console = get_console()\n",
    "console.is_jupyter = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be57afbc-1ef0-4e96-8129-e8c9824d8830",
   "metadata": {},
   "source": [
    "# PydanticAI Agents\n",
    "\n",
    "In our previous post, we explored function calling and how it enables models to interact with external tools. It’s a powerful feature, but manually defining schemas and managing the request/response loop can become tedious as an application grows. This is where agent frameworks come in.\n",
    "\n",
    "In this post, let’s experiment with [PydanticAI Agents](https://ai.pydantic.dev/agents/). We’ll use it to define a simple agent that mimics our earlier examples, but with  less boilerplate. We will also inspect the underlying requests to try and learn how the framework orchestrates tool calls, and finally, we'll test how well it handles swapping the backend model for a local instance running via Ollama.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Follow the README instructions to set up your Python environment.\n",
    "\n",
    "For the code examples that use local models, we'll be using Ollama's `llama3.2` model. If you haven't done so already, [install Ollama](https://ollama.com/download) on your computer and download the model with `ollama pull llama3.2`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a136621",
   "metadata": {},
   "source": [
    "### Agent: Name Cactifier\n",
    "\n",
    "To get a feel for the syntax, let's bring back the `cactify_name` example we used in previous posts. Using PydanticAI, we can take that same logic and register it directly to the agent, bypassing the need to write out the raw schema definition manually, and letting the framework handle the request/response loop for us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dda19764-91ec-428d-98bf-07db4ed8cbea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: The cactus-ified version of the name Alice is \"Alicactus\"!\n"
     ]
    }
   ],
   "source": [
    "from pydantic_ai import Agent\n",
    "\n",
    "agent = Agent(\n",
    "    name=\"Name Cactifier\",\n",
    "    model=\"openai:gpt-4o-mini\",\n",
    "    instructions=\"You are a friendly agent that transforms people's names to make them more cactus-like using specific rules.\",\n",
    ")\n",
    "\n",
    "\n",
    "@agent.tool_plain\n",
    "def cactify_name(name: str) -> str:\n",
    "    \"\"\"Makes a name more cactus-like.\"\"\"\n",
    "    base_name = name\n",
    "    if base_name.lower().endswith((\"s\", \"x\")):\n",
    "        base_name = base_name[:-1]\n",
    "    if base_name and base_name.lower()[-1] in \"aeiou\":\n",
    "        base_name = base_name[:-1]\n",
    "    return base_name + \"actus\"\n",
    "\n",
    "\n",
    "result1 = await agent.run(\"What would the name Alice be if it were cactus-ified?\")\n",
    "print(\"Response:\", result1.output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783a18e2",
   "metadata": {},
   "source": [
    "When we run this, the agent recognizes it needs to use the tool and returns the cactified name as expected.\n",
    "\n",
    "That's a lot less code! But how does it work?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11821aa",
   "metadata": {},
   "source": [
    "The [`AgentRunResult.all_messages()`](https://ai.pydantic.dev/api/agent/#pydantic_ai.agent.AgentRunResult.all_messages) method returns the conversation history as a list of [ModelMessage](https://ai.pydantic.dev/api/messages/#pydantic_ai.messages.ModelMessage) objects, which is quite verbose. To make it easier to read, we'll strip out some of the less relevant fields for brevity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8a88e21-7d92-48b4-9bc6-b9a6c24aaf86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m[\u001b[0m\n",
      "  \u001b[1m{\u001b[0m\n",
      "    \u001b[1;34m\"ModelRequest\"\u001b[0m: \u001b[1m{\u001b[0m\n",
      "      \u001b[1;34m\"parts\"\u001b[0m: \u001b[1m[\u001b[0m\n",
      "        \u001b[1m{\u001b[0m\n",
      "          \u001b[1;34m\"UserPromptPart\"\u001b[0m: \u001b[1m{\u001b[0m\n",
      "            \u001b[1;34m\"content\"\u001b[0m: \u001b[32m\"What would the name Alice be if it were cactus-ified?\"\u001b[0m\n",
      "          \u001b[1m}\u001b[0m\n",
      "        \u001b[1m}\u001b[0m\n",
      "      \u001b[1m]\u001b[0m,\n",
      "      \u001b[1;34m\"instructions\"\u001b[0m: \u001b[32m\"You are a friendly agent that transforms people's names to make them more cactus-like using specific rules.\"\u001b[0m\n",
      "    \u001b[1m}\u001b[0m\n",
      "  \u001b[1m}\u001b[0m,\n",
      "  \u001b[1m{\u001b[0m\n",
      "    \u001b[1;34m\"ModelResponse\"\u001b[0m: \u001b[1m{\u001b[0m\n",
      "      \u001b[1;34m\"parts\"\u001b[0m: \u001b[1m[\u001b[0m\n",
      "        \u001b[1m{\u001b[0m\n",
      "          \u001b[1;34m\"ToolCallPart\"\u001b[0m: \u001b[1m{\u001b[0m\n",
      "            \u001b[1;34m\"tool_name\"\u001b[0m: \u001b[32m\"cactify_name\"\u001b[0m,\n",
      "            \u001b[1;34m\"args\"\u001b[0m: \u001b[32m\"{\\\"name\\\":\\\"Alice\\\"}\"\u001b[0m\n",
      "          \u001b[1m}\u001b[0m\n",
      "        \u001b[1m}\u001b[0m\n",
      "      \u001b[1m]\u001b[0m\n",
      "    \u001b[1m}\u001b[0m\n",
      "  \u001b[1m}\u001b[0m,\n",
      "  \u001b[1m{\u001b[0m\n",
      "    \u001b[1;34m\"ModelRequest\"\u001b[0m: \u001b[1m{\u001b[0m\n",
      "      \u001b[1;34m\"parts\"\u001b[0m: \u001b[1m[\u001b[0m\n",
      "        \u001b[1m{\u001b[0m\n",
      "          \u001b[1;34m\"ToolReturnPart\"\u001b[0m: \u001b[1m{\u001b[0m\n",
      "            \u001b[1;34m\"tool_name\"\u001b[0m: \u001b[32m\"cactify_name\"\u001b[0m,\n",
      "            \u001b[1;34m\"content\"\u001b[0m: \u001b[32m\"Alicactus\"\u001b[0m\n",
      "          \u001b[1m}\u001b[0m\n",
      "        \u001b[1m}\u001b[0m\n",
      "      \u001b[1m]\u001b[0m,\n",
      "      \u001b[1;34m\"instructions\"\u001b[0m: \u001b[32m\"You are a friendly agent that transforms people's names to make them more cactus-like using specific rules.\"\u001b[0m\n",
      "    \u001b[1m}\u001b[0m\n",
      "  \u001b[1m}\u001b[0m,\n",
      "  \u001b[1m{\u001b[0m\n",
      "    \u001b[1;34m\"ModelResponse\"\u001b[0m: \u001b[1m{\u001b[0m\n",
      "      \u001b[1;34m\"parts\"\u001b[0m: \u001b[1m[\u001b[0m\n",
      "        \u001b[1m{\u001b[0m\n",
      "          \u001b[1;34m\"TextPart\"\u001b[0m: \u001b[1m{\u001b[0m\n",
      "            \u001b[1;34m\"content\"\u001b[0m: \u001b[32m\"The cactus-ified version of the name Alice is \\\"Alicactus\\\"!\"\u001b[0m\n",
      "          \u001b[1m}\u001b[0m\n",
      "        \u001b[1m}\u001b[0m\n",
      "      \u001b[1m]\u001b[0m\n",
      "    \u001b[1m}\u001b[0m\n",
      "  \u001b[1m}\u001b[0m\n",
      "\u001b[1m]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from notebooks.pydantic_models import print_all_messages\n",
    "\n",
    "print_all_messages(result1.all_messages())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d056646",
   "metadata": {},
   "source": [
    "The output shows the complete conversation flow:\n",
    "\n",
    "1. **ModelRequest** - The user's prompt (\"What would the name Alice be if it were cactus-ified?\") and the models instructions.\n",
    "2. **ModelResponse** - The model's decision to call the `cactify_name` tool with `{\"name\": \"Alice\"}`\n",
    "3. **ModelRequest** - The tool's return value (`\"Alicactus\"`) sent back to the model\n",
    "4. **ModelResponse** - The model's final text response incorporating the tool result\n",
    "\n",
    "This illustrates the agent loop: user prompt → tool call → tool execution → final response."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e6dfcc",
   "metadata": {},
   "source": [
    "## Llama 3.2 via Ollama\n",
    "\n",
    "PydanticAI supports various model backends, including local models via Ollama. To switch to a local model, simply change the `model` parameter when creating the agent or when running it.\n",
    "\n",
    "When we run the agent again with the same prompt, it successfully uses the local `llama3.2` model to cactify the name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1947708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: If the original name was \"Alice\", the cactus-ified version is indeed \"Alicactus\". This transformation involves adding a \"-cactus\" suffix to the end of the given name, resulting in a unique and prickly cactus-inspired alternative. Would you like me to cactus-fy another name?\n"
     ]
    }
   ],
   "source": [
    "result2 = await agent.run(\n",
    "    \"What would the name Alice be if it were cactus-ified?\",\n",
    "    model=\"ollama:llama3.2\",\n",
    ")\n",
    "print(\"Response:\", result2.output)\n",
    "# print_all_messages(result2.all_messages())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c869ec3f",
   "metadata": {},
   "source": [
    "## OpenAI-compatible Providers\n",
    "\n",
    "Inspecting `all_messages()` is helpful, but the abstraction can hide details. What is actually sent to the model provider?\n",
    "\n",
    "Pydantic offers [Logfire](https://ai.pydantic.dev/logfire/), which is very useful for monitoring and debugging LLM interactions, but here we just want to log the raw requests and responses (including the payloads) to the console for a quick look. We wrote a simple helper that taps into the httpx event hooks to print the request and response data and we'll use it with our Ollama model:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93158479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;36m>>> REQUEST\u001b[0m POST \u001b[4;94mhttp://localhost:11434/v1/chat/completions\u001b[0m\n",
      "\u001b[1m{\u001b[0m\n",
      "  \u001b[1;34m\"messages\"\u001b[0m: \u001b[1m[\u001b[0m\n",
      "    \u001b[1m{\u001b[0m\n",
      "      \u001b[1;34m\"content\"\u001b[0m: \u001b[32m\"You are a friendly agent that transforms people's names to make them more cactus-like using specific rules.\"\u001b[0m,\n",
      "      \u001b[1;34m\"role\"\u001b[0m: \u001b[32m\"system\"\u001b[0m\n",
      "    \u001b[1m}\u001b[0m,\n",
      "    \u001b[1m{\u001b[0m\n",
      "      \u001b[1;34m\"role\"\u001b[0m: \u001b[32m\"user\"\u001b[0m,\n",
      "      \u001b[1;34m\"content\"\u001b[0m: \u001b[32m\"What would the name Alice be if it were cactus-ified?\"\u001b[0m\n",
      "    \u001b[1m}\u001b[0m\n",
      "  \u001b[1m]\u001b[0m,\n",
      "  \u001b[1;34m\"model\"\u001b[0m: \u001b[32m\"llama3.2\"\u001b[0m,\n",
      "  \u001b[1;34m\"stream\"\u001b[0m: \u001b[3;91mfalse\u001b[0m,\n",
      "  \u001b[1;34m\"tool_choice\"\u001b[0m: \u001b[32m\"auto\"\u001b[0m,\n",
      "  \u001b[1;34m\"tools\"\u001b[0m: \u001b[1m[\u001b[0m\n",
      "    \u001b[1m{\u001b[0m\n",
      "      \u001b[1;34m\"type\"\u001b[0m: \u001b[32m\"function\"\u001b[0m,\n",
      "      \u001b[1;34m\"function\"\u001b[0m: \u001b[1m{\u001b[0m\n",
      "        \u001b[1;34m\"name\"\u001b[0m: \u001b[32m\"cactify_name\"\u001b[0m,\n",
      "        \u001b[1;34m\"description\"\u001b[0m: \u001b[32m\"Makes a name more cactus-like.\"\u001b[0m,\n",
      "        \u001b[1;34m\"parameters\"\u001b[0m: \u001b[1m{\u001b[0m\n",
      "          \u001b[1;34m\"additionalProperties\"\u001b[0m: \u001b[3;91mfalse\u001b[0m,\n",
      "          \u001b[1;34m\"properties\"\u001b[0m: \u001b[1m{\u001b[0m\n",
      "            \u001b[1;34m\"name\"\u001b[0m: \u001b[1m{\u001b[0m\n",
      "              \u001b[1;34m\"type\"\u001b[0m: \u001b[32m\"string\"\u001b[0m\n",
      "            \u001b[1m}\u001b[0m\n",
      "          \u001b[1m}\u001b[0m,\n",
      "          \u001b[1;34m\"required\"\u001b[0m: \u001b[1m[\u001b[0m\n",
      "            \u001b[32m\"name\"\u001b[0m\n",
      "          \u001b[1m]\u001b[0m,\n",
      "          \u001b[1;34m\"type\"\u001b[0m: \u001b[32m\"object\"\u001b[0m\n",
      "        \u001b[1m}\u001b[0m,\n",
      "        \u001b[1;34m\"strict\"\u001b[0m: \u001b[3;92mtrue\u001b[0m\n",
      "      \u001b[1m}\u001b[0m\n",
      "    \u001b[1m}\u001b[0m\n",
      "  \u001b[1m]\u001b[0m\n",
      "\u001b[1m}\u001b[0m\n",
      "\u001b[1;32m<<< RESPONSE\u001b[0m \u001b[1;36m200\u001b[0m\n",
      "\u001b[1m{\u001b[0m\n",
      "  \u001b[1;34m\"id\"\u001b[0m: \u001b[32m\"chatcmpl-702\"\u001b[0m,\n",
      "  \u001b[1;34m\"object\"\u001b[0m: \u001b[32m\"chat.completion\"\u001b[0m,\n",
      "  \u001b[1;34m\"created\"\u001b[0m: \u001b[1;36m1765566333\u001b[0m,\n",
      "  \u001b[1;34m\"model\"\u001b[0m: \u001b[32m\"llama3.2\"\u001b[0m,\n",
      "  \u001b[1;34m\"system_fingerprint\"\u001b[0m: \u001b[32m\"fp_ollama\"\u001b[0m,\n",
      "  \u001b[1;34m\"choices\"\u001b[0m: \u001b[1m[\u001b[0m\n",
      "    \u001b[1m{\u001b[0m\n",
      "      \u001b[1;34m\"index\"\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
      "      \u001b[1;34m\"message\"\u001b[0m: \u001b[1m{\u001b[0m\n",
      "        \u001b[1;34m\"role\"\u001b[0m: \u001b[32m\"assistant\"\u001b[0m,\n",
      "        \u001b[1;34m\"content\"\u001b[0m: \u001b[32m\"\"\u001b[0m,\n",
      "        \u001b[1;34m\"tool_calls\"\u001b[0m: \u001b[1m[\u001b[0m\n",
      "          \u001b[1m{\u001b[0m\n",
      "            \u001b[1;34m\"id\"\u001b[0m: \u001b[32m\"call_aj5cxrw6\"\u001b[0m,\n",
      "            \u001b[1;34m\"index\"\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
      "            \u001b[1;34m\"type\"\u001b[0m: \u001b[32m\"function\"\u001b[0m,\n",
      "            \u001b[1;34m\"function\"\u001b[0m: \u001b[1m{\u001b[0m\n",
      "              \u001b[1;34m\"name\"\u001b[0m: \u001b[32m\"cactify_name\"\u001b[0m,\n",
      "              \u001b[1;34m\"arguments\"\u001b[0m: \u001b[32m\"{\\\"name\\\":\\\"Alice\\\"}\"\u001b[0m\n",
      "            \u001b[1m}\u001b[0m\n",
      "          \u001b[1m}\u001b[0m\n",
      "        \u001b[1m]\u001b[0m\n",
      "      \u001b[1m}\u001b[0m,\n",
      "      \u001b[1;34m\"finish_reason\"\u001b[0m: \u001b[32m\"tool_calls\"\u001b[0m\n",
      "    \u001b[1m}\u001b[0m\n",
      "  \u001b[1m]\u001b[0m,\n",
      "  \u001b[1;34m\"usage\"\u001b[0m: \u001b[1m{\u001b[0m\n",
      "    \u001b[1;34m\"prompt_tokens\"\u001b[0m: \u001b[1;36m186\u001b[0m,\n",
      "    \u001b[1;34m\"completion_tokens\"\u001b[0m: \u001b[1;36m15\u001b[0m,\n",
      "    \u001b[1;34m\"total_tokens\"\u001b[0m: \u001b[1;36m201\u001b[0m\n",
      "  \u001b[1m}\u001b[0m\n",
      "\u001b[1m}\u001b[0m\n",
      "\u001b[1;36m>>> REQUEST\u001b[0m POST \u001b[4;94mhttp://localhost:11434/v1/chat/completions\u001b[0m\n",
      "\u001b[1m{\u001b[0m\n",
      "  \u001b[1;34m\"messages\"\u001b[0m: \u001b[1m[\u001b[0m\n",
      "    \u001b[1m{\u001b[0m\n",
      "      \u001b[1;34m\"content\"\u001b[0m: \u001b[32m\"You are a friendly agent that transforms people's names to make them more cactus-like using specific rules.\"\u001b[0m,\n",
      "      \u001b[1;34m\"role\"\u001b[0m: \u001b[32m\"system\"\u001b[0m\n",
      "    \u001b[1m}\u001b[0m,\n",
      "    \u001b[1m{\u001b[0m\n",
      "      \u001b[1;34m\"role\"\u001b[0m: \u001b[32m\"user\"\u001b[0m,\n",
      "      \u001b[1;34m\"content\"\u001b[0m: \u001b[32m\"What would the name Alice be if it were cactus-ified?\"\u001b[0m\n",
      "    \u001b[1m}\u001b[0m,\n",
      "    \u001b[1m{\u001b[0m\n",
      "      \u001b[1;34m\"role\"\u001b[0m: \u001b[32m\"assistant\"\u001b[0m,\n",
      "      \u001b[1;34m\"content\"\u001b[0m: \u001b[3;35mnull\u001b[0m,\n",
      "      \u001b[1;34m\"tool_calls\"\u001b[0m: \u001b[1m[\u001b[0m\n",
      "        \u001b[1m{\u001b[0m\n",
      "          \u001b[1;34m\"id\"\u001b[0m: \u001b[32m\"call_aj5cxrw6\"\u001b[0m,\n",
      "          \u001b[1;34m\"type\"\u001b[0m: \u001b[32m\"function\"\u001b[0m,\n",
      "          \u001b[1;34m\"function\"\u001b[0m: \u001b[1m{\u001b[0m\n",
      "            \u001b[1;34m\"name\"\u001b[0m: \u001b[32m\"cactify_name\"\u001b[0m,\n",
      "            \u001b[1;34m\"arguments\"\u001b[0m: \u001b[32m\"{\\\"name\\\":\\\"Alice\\\"}\"\u001b[0m\n",
      "          \u001b[1m}\u001b[0m\n",
      "        \u001b[1m}\u001b[0m\n",
      "      \u001b[1m]\u001b[0m\n",
      "    \u001b[1m}\u001b[0m,\n",
      "    \u001b[1m{\u001b[0m\n",
      "      \u001b[1;34m\"role\"\u001b[0m: \u001b[32m\"tool\"\u001b[0m,\n",
      "      \u001b[1;34m\"tool_call_id\"\u001b[0m: \u001b[32m\"call_aj5cxrw6\"\u001b[0m,\n",
      "      \u001b[1;34m\"content\"\u001b[0m: \u001b[32m\"Alicactus\"\u001b[0m\n",
      "    \u001b[1m}\u001b[0m\n",
      "  \u001b[1m]\u001b[0m,\n",
      "  \u001b[1;34m\"model\"\u001b[0m: \u001b[32m\"llama3.2\"\u001b[0m,\n",
      "  \u001b[1;34m\"stream\"\u001b[0m: \u001b[3;91mfalse\u001b[0m,\n",
      "  \u001b[1;34m\"tool_choice\"\u001b[0m: \u001b[32m\"auto\"\u001b[0m,\n",
      "  \u001b[1;34m\"tools\"\u001b[0m: \u001b[1m[\u001b[0m\n",
      "    \u001b[1m{\u001b[0m\n",
      "      \u001b[1;34m\"type\"\u001b[0m: \u001b[32m\"function\"\u001b[0m,\n",
      "      \u001b[1;34m\"function\"\u001b[0m: \u001b[1m{\u001b[0m\n",
      "        \u001b[1;34m\"name\"\u001b[0m: \u001b[32m\"cactify_name\"\u001b[0m,\n",
      "        \u001b[1;34m\"description\"\u001b[0m: \u001b[32m\"Makes a name more cactus-like.\"\u001b[0m,\n",
      "        \u001b[1;34m\"parameters\"\u001b[0m: \u001b[1m{\u001b[0m\n",
      "          \u001b[1;34m\"additionalProperties\"\u001b[0m: \u001b[3;91mfalse\u001b[0m,\n",
      "          \u001b[1;34m\"properties\"\u001b[0m: \u001b[1m{\u001b[0m\n",
      "            \u001b[1;34m\"name\"\u001b[0m: \u001b[1m{\u001b[0m\n",
      "              \u001b[1;34m\"type\"\u001b[0m: \u001b[32m\"string\"\u001b[0m\n",
      "            \u001b[1m}\u001b[0m\n",
      "          \u001b[1m}\u001b[0m,\n",
      "          \u001b[1;34m\"required\"\u001b[0m: \u001b[1m[\u001b[0m\n",
      "            \u001b[32m\"name\"\u001b[0m\n",
      "          \u001b[1m]\u001b[0m,\n",
      "          \u001b[1;34m\"type\"\u001b[0m: \u001b[32m\"object\"\u001b[0m\n",
      "        \u001b[1m}\u001b[0m,\n",
      "        \u001b[1;34m\"strict\"\u001b[0m: \u001b[3;92mtrue\u001b[0m\n",
      "      \u001b[1m}\u001b[0m\n",
      "    \u001b[1m}\u001b[0m\n",
      "  \u001b[1m]\u001b[0m\n",
      "\u001b[1m}\u001b[0m\n",
      "\u001b[1;32m<<< RESPONSE\u001b[0m \u001b[1;36m200\u001b[0m\n",
      "\u001b[1m{\u001b[0m\n",
      "  \u001b[1;34m\"id\"\u001b[0m: \u001b[32m\"chatcmpl-963\"\u001b[0m,\n",
      "  \u001b[1;34m\"object\"\u001b[0m: \u001b[32m\"chat.completion\"\u001b[0m,\n",
      "  \u001b[1;34m\"created\"\u001b[0m: \u001b[1;36m1765566334\u001b[0m,\n",
      "  \u001b[1;34m\"model\"\u001b[0m: \u001b[32m\"llama3.2\"\u001b[0m,\n",
      "  \u001b[1;34m\"system_fingerprint\"\u001b[0m: \u001b[32m\"fp_ollama\"\u001b[0m,\n",
      "  \u001b[1;34m\"choices\"\u001b[0m: \u001b[1m[\u001b[0m\n",
      "    \u001b[1m{\u001b[0m\n",
      "      \u001b[1;34m\"index\"\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
      "      \u001b[1;34m\"message\"\u001b[0m: \u001b[1m{\u001b[0m\n",
      "        \u001b[1;34m\"role\"\u001b[0m: \u001b[32m\"assistant\"\u001b[0m,\n",
      "        \u001b[1;34m\"content\"\u001b[0m: \u001b[32m\"If the original name is Alice, applying the cactus-ification rules results in Alicactus. The process involves replacing certain letters with more spiny alternatives, transforming it into a unique and prickly-sounding name reminiscent of the desert flora.\"\u001b[0m\n",
      "      \u001b[1m}\u001b[0m,\n",
      "      \u001b[1;34m\"finish_reason\"\u001b[0m: \u001b[32m\"stop\"\u001b[0m\n",
      "    \u001b[1m}\u001b[0m\n",
      "  \u001b[1m]\u001b[0m,\n",
      "  \u001b[1;34m\"usage\"\u001b[0m: \u001b[1m{\u001b[0m\n",
      "    \u001b[1;34m\"prompt_tokens\"\u001b[0m: \u001b[1;36m122\u001b[0m,\n",
      "    \u001b[1;34m\"completion_tokens\"\u001b[0m: \u001b[1;36m49\u001b[0m,\n",
      "    \u001b[1;34m\"total_tokens\"\u001b[0m: \u001b[1;36m171\u001b[0m\n",
      "  \u001b[1m}\u001b[0m\n",
      "\u001b[1m}\u001b[0m\n",
      "Response: If the original name is Alice, applying the cactus-ification rules results in Alicactus. The process involves replacing certain letters with more spiny alternatives, transforming it into a unique and prickly-sounding name reminiscent of the desert flora.\n"
     ]
    }
   ],
   "source": [
    "from notebooks.pydantic_models import get_model\n",
    "\n",
    "llama32_model_with_logging = get_model(\"ollama:llama3.2\", debug_http=True)\n",
    "result3 = await agent.run(\n",
    "    \"What would the name Alice be if it were cactus-ified?\",\n",
    "    model=llama32_model_with_logging,\n",
    ")\n",
    "print(\"Response:\", result3.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3eff50b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bd2d42d6",
   "metadata": {},
   "source": [
    "### Non-text response\n",
    "\n",
    "What if our tool returned a non-text response, like a dictionary of the original name and the cactified version? Let's modify our tool to do that:\n",
    "\n",
    "```python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d6555ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: original_name='Alice' cactified_name='Alicactus'\n",
      "\u001b[1m[\u001b[0m\n",
      "  \u001b[1m{\u001b[0m\n",
      "    \u001b[1;34m\"ModelRequest\"\u001b[0m: \u001b[1m{\u001b[0m\n",
      "      \u001b[1;34m\"parts\"\u001b[0m: \u001b[1m[\u001b[0m\n",
      "        \u001b[1m{\u001b[0m\n",
      "          \u001b[1;34m\"UserPromptPart\"\u001b[0m: \u001b[1m{\u001b[0m\n",
      "            \u001b[1;34m\"content\"\u001b[0m: \u001b[32m\"What would the name Alice be if it were cactus-ified?\"\u001b[0m\n",
      "          \u001b[1m}\u001b[0m\n",
      "        \u001b[1m}\u001b[0m\n",
      "      \u001b[1m]\u001b[0m,\n",
      "      \u001b[1;34m\"instructions\"\u001b[0m: \u001b[32m\"You are a friendly agent that transforms people's names to make them more cactus-like using specific rules. You MUST call a tool when answering user questions if any tool is relevant. Never answer directly.\"\u001b[0m\n",
      "    \u001b[1m}\u001b[0m\n",
      "  \u001b[1m}\u001b[0m,\n",
      "  \u001b[1m{\u001b[0m\n",
      "    \u001b[1;34m\"ModelResponse\"\u001b[0m: \u001b[1m{\u001b[0m\n",
      "      \u001b[1;34m\"parts\"\u001b[0m: \u001b[1m[\u001b[0m\n",
      "        \u001b[1m{\u001b[0m\n",
      "          \u001b[1;34m\"ToolCallPart\"\u001b[0m: \u001b[1m{\u001b[0m\n",
      "            \u001b[1;34m\"tool_name\"\u001b[0m: \u001b[32m\"cactify_name2\"\u001b[0m,\n",
      "            \u001b[1;34m\"args\"\u001b[0m: \u001b[32m\"{\\\"name\\\":\\\"Alice\\\"}\"\u001b[0m\n",
      "          \u001b[1m}\u001b[0m\n",
      "        \u001b[1m}\u001b[0m\n",
      "      \u001b[1m]\u001b[0m\n",
      "    \u001b[1m}\u001b[0m\n",
      "  \u001b[1m}\u001b[0m,\n",
      "  \u001b[1m{\u001b[0m\n",
      "    \u001b[1;34m\"ModelRequest\"\u001b[0m: \u001b[1m{\u001b[0m\n",
      "      \u001b[1;34m\"parts\"\u001b[0m: \u001b[1m[\u001b[0m\n",
      "        \u001b[1m{\u001b[0m\n",
      "          \u001b[1;34m\"ToolReturnPart\"\u001b[0m: \u001b[1m{\u001b[0m\n",
      "            \u001b[1;34m\"tool_name\"\u001b[0m: \u001b[32m\"cactify_name2\"\u001b[0m,\n",
      "            \u001b[1;34m\"content\"\u001b[0m: \u001b[32m\"Alicactus\"\u001b[0m\n",
      "          \u001b[1m}\u001b[0m\n",
      "        \u001b[1m}\u001b[0m\n",
      "      \u001b[1m]\u001b[0m,\n",
      "      \u001b[1;34m\"instructions\"\u001b[0m: \u001b[32m\"You are a friendly agent that transforms people's names to make them more cactus-like using specific rules. You MUST call a tool when answering user questions if any tool is relevant. Never answer directly.\"\u001b[0m\n",
      "    \u001b[1m}\u001b[0m\n",
      "  \u001b[1m}\u001b[0m,\n",
      "  \u001b[1m{\u001b[0m\n",
      "    \u001b[1;34m\"ModelResponse\"\u001b[0m: \u001b[1m{\u001b[0m\n",
      "      \u001b[1;34m\"parts\"\u001b[0m: \u001b[1m[\u001b[0m\n",
      "        \u001b[1m{\u001b[0m\n",
      "          \u001b[1;34m\"ToolCallPart\"\u001b[0m: \u001b[1m{\u001b[0m\n",
      "            \u001b[1;34m\"tool_name\"\u001b[0m: \u001b[32m\"final_result\"\u001b[0m,\n",
      "            \u001b[1;34m\"args\"\u001b[0m: \u001b[32m\"{\\\"original_name\\\":\\\"Alice\\\",\\\"cactified_name\\\":\\\"Alicactus\\\"}\"\u001b[0m\n",
      "          \u001b[1m}\u001b[0m\n",
      "        \u001b[1m}\u001b[0m\n",
      "      \u001b[1m]\u001b[0m\n",
      "    \u001b[1m}\u001b[0m\n",
      "  \u001b[1m}\u001b[0m,\n",
      "  \u001b[1m{\u001b[0m\n",
      "    \u001b[1;34m\"ModelRequest\"\u001b[0m: \u001b[1m{\u001b[0m\n",
      "      \u001b[1;34m\"parts\"\u001b[0m: \u001b[1m[\u001b[0m\n",
      "        \u001b[1m{\u001b[0m\n",
      "          \u001b[1;34m\"ToolReturnPart\"\u001b[0m: \u001b[1m{\u001b[0m\n",
      "            \u001b[1;34m\"tool_name\"\u001b[0m: \u001b[32m\"final_result\"\u001b[0m,\n",
      "            \u001b[1;34m\"content\"\u001b[0m: \u001b[32m\"Final result processed.\"\u001b[0m\n",
      "          \u001b[1m}\u001b[0m\n",
      "        \u001b[1m}\u001b[0m\n",
      "      \u001b[1m]\u001b[0m,\n",
      "      \u001b[1;34m\"instructions\"\u001b[0m: \u001b[3;35mnull\u001b[0m\n",
      "    \u001b[1m}\u001b[0m\n",
      "  \u001b[1m}\u001b[0m\n",
      "\u001b[1m]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "class NameResponse(BaseModel):\n",
    "    original_name: str\n",
    "    cactified_name: str\n",
    "\n",
    "\n",
    "agent2 = Agent(\n",
    "    name=\"Name Cactifier\",\n",
    "    model=\"openai:gpt-4o-mini\",\n",
    "    instructions=\"You are a friendly agent that transforms people's names to make them more cactus-like using specific rules. You MUST call a tool when answering user questions if any tool is relevant. Never answer directly.\",\n",
    "    output_type=NameResponse,\n",
    ")\n",
    "\n",
    "\n",
    "@agent2.tool_plain\n",
    "def cactify_name2(name: str) -> str:\n",
    "    \"\"\"Makes a name more cactus-like.\"\"\"\n",
    "    base_name = name\n",
    "    if base_name.lower().endswith((\"s\", \"x\")):\n",
    "        base_name = base_name[:-1]\n",
    "    if base_name and base_name.lower()[-1] in \"aeiou\":\n",
    "        base_name = base_name[:-1]\n",
    "    return base_name + \"actus\"\n",
    "\n",
    "\n",
    "result2 = await agent2.run(\"What would the name Alice be if it were cactus-ified?\")\n",
    "print(\"Response:\", result2.output)\n",
    "print_all_messages(result2.all_messages())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-learning (3.13.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
