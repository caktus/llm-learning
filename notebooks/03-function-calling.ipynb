{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cc7ee8b",
   "metadata": {},
   "source": [
    "# Function Calling\n",
    "\n",
    "Function calling allows you to define functions (with schemas) that the model can call as part of its response, enabling structured outputs, tool use, and more advanced workflows. \n",
    "\n",
    "For us, this seems like a first step towards our goal of enabling more complex interactions with LLMs, where they can not only generate text but also perform actions based on that text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7abe1d5",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "Make sure you have your OpenAI API key set up as described in the previous notebook. We'll use the Python SDK for these examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "027b4309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VS Code's Jupyter extension doesn't support loading .envrc, so if you're using VS Code, we load it here.\n",
    "\n",
    "from utils import load_envrc\n",
    "\n",
    "load_envrc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3173ec48",
   "metadata": {},
   "source": [
    "## Defining a function schema\n",
    "\n",
    "We need to define a function that the model can use. Here we'll use a silly example function that \"cactifies\" a name. The schema for the function is defined in [JSON Schema format](https://json-schema.org/docs) and looks like this:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"name\": \"cactify_name\",\n",
    "  \"type\": \"function\",\n",
    "  \"description\": \"Transforms a name into a fun, cactus-themed version.\",\n",
    "  \"parameters\": {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "      \"name\": {\n",
    "        \"type\": \"string\",\n",
    "        \"description\": \"The name to be cactified.\"\n",
    "      }\n",
    "    },\n",
    "    \"required\": [\"name\"]\n",
    "  }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc06e866",
   "metadata": {},
   "source": [
    "Following the [OpenAI function calling docs](https://platform.openai.com/docs/guides/function-calling), we can pass a `tools` parameter to the API endpoint to define functions the model can call. Here we use `curl` to demonstrate the raw API request:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8b7b3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash --out curl_response\n",
    "\n",
    "curl https://api.openai.com/v1/responses -s \\\n",
    "  -H \"Content-Type: application/json\" \\\n",
    "  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n",
    "  -d '{\n",
    "    \"model\": \"gpt-5-nano\",\n",
    "    \"input\": [\n",
    "      {\"role\": \"user\", \"content\": \"What would my name, Colin, be if it were cactus-ified?\"}\n",
    "    ],\n",
    "    \"tools\": [\n",
    "      {\n",
    "        \"name\": \"cactify_name\",\n",
    "        \"type\": \"function\",\n",
    "        \"description\": \"Transforms a name into a fun, cactus-themed version.\",\n",
    "        \"parameters\": {\n",
    "          \"type\": \"object\",\n",
    "          \"properties\": {\n",
    "            \"name\": {\n",
    "              \"type\": \"string\",\n",
    "              \"description\": \"The name to be made cactus-like.\"\n",
    "            }\n",
    "          },\n",
    "          \"required\": [\"name\"]\n",
    "        }\n",
    "      }\n",
    "    ]\n",
    "  }'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4353f624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'rs_0f6c0809e42d76950068c9d7930b748197a68348c3650098f5'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'reasoning'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'summary'</span>: <span style=\"font-weight: bold\">[]}</span>,\n",
       "    <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'fc_0f6c0809e42d76950068c9d793d714819793a8a604b41f8a10'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'function_call'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'status'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'completed'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'arguments'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'{\"name\":\"Colin\"}'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'call_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'call_eckxIyxX7yoEpszYMLzCblmx'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'cactify_name'</span>\n",
       "    <span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[1m{\u001b[0m\u001b[32m'id'\u001b[0m: \u001b[32m'rs_0f6c0809e42d76950068c9d7930b748197a68348c3650098f5'\u001b[0m, \u001b[32m'type'\u001b[0m: \u001b[32m'reasoning'\u001b[0m, \u001b[32m'summary'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'id'\u001b[0m: \u001b[32m'fc_0f6c0809e42d76950068c9d793d714819793a8a604b41f8a10'\u001b[0m,\n",
       "        \u001b[32m'type'\u001b[0m: \u001b[32m'function_call'\u001b[0m,\n",
       "        \u001b[32m'status'\u001b[0m: \u001b[32m'completed'\u001b[0m,\n",
       "        \u001b[32m'arguments'\u001b[0m: \u001b[32m'\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\"name\":\"Colin\"\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m,\n",
       "        \u001b[32m'call_id'\u001b[0m: \u001b[32m'call_eckxIyxX7yoEpszYMLzCblmx'\u001b[0m,\n",
       "        \u001b[32m'name'\u001b[0m: \u001b[32m'cactify_name'\u001b[0m\n",
       "    \u001b[1m}\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "from rich import print as rich_print\n",
    "\n",
    "data = json.loads(curl_response)  # noqa\n",
    "rich_print(data[\"output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be67a366",
   "metadata": {},
   "source": [
    "Reviewing the output, we see that the model decided to call our `cactify_name` function with the argument `\"Colin\"`. The model itself doesn't actually execute the function. It simply returns the function call in its response. It's up to us to handle the function execution and return the result if needed.\n",
    "\n",
    "It's easier to see this in action using the Python SDK, which we'll explore next."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4c187a",
   "metadata": {},
   "source": [
    "## Using the Python SDK\n",
    "\n",
    "Now let's see how to do the same thing using the Python SDK. We'll define the function schema as a variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c534b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cactify_name_schema = {\n",
    "    \"name\": \"cactify_name\",\n",
    "    \"type\": \"function\",\n",
    "    \"description\": \"Transform a name into a fun, cactus-themed version.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\"name\": {\"type\": \"string\", \"description\": \"The name to be cactified.\"}},\n",
    "        \"required\": [\"name\"],\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4dbdf2",
   "metadata": {},
   "source": [
    "## Making a function call request\n",
    "\n",
    "Now, let's ask the model to cactify a name using the function we defined:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a30d82c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Response</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'resp_07760e000eb25cdc0068c9d79c004481a3a09c1dfaefe39d87'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">created_at</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1758058396.0</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">error</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">incomplete_details</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">instructions</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-5-nano-2025-08-07'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'response'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">output</span>=<span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ResponseReasoningItem</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'rs_07760e000eb25cdc0068c9d79d790881a3a2054d2db49f34ae'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">summary</span>=<span style=\"font-weight: bold\">[]</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'reasoning'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">encrypted_content</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">status</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ResponseFunctionToolCall</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">arguments</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'{\"name\":\"Colin\"}'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">call_id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'call_y8ouIrJZrcKo0BCIP8UCSuVK'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'cactify_name'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'function_call'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'fc_07760e000eb25cdc0068c9d79e50ac81a3b4273b683a1e7e1d'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">status</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'completed'</span>\n",
       "        <span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">parallel_tool_calls</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">temperature</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">tool_choice</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'auto'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">tools</span>=<span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">FunctionTool</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'cactify_name'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">parameters</span>=<span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'object'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'properties'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'string'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'description'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'The name to be cactified.'</span><span style=\"font-weight: bold\">}}</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'required'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'name'</span><span style=\"font-weight: bold\">]</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'additionalProperties'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>\n",
       "            <span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">strict</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'function'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">description</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Transform a name into a fun, cactus-themed version.'</span>\n",
       "        <span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">top_p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">background</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">conversation</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">max_output_tokens</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">max_tool_calls</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">previous_response_id</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">prompt</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">prompt_cache_key</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">reasoning</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Reasoning</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">effort</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'medium'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">generate_summary</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, <span style=\"color: #808000; text-decoration-color: #808000\">summary</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">safety_identifier</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">service_tier</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'default'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">status</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'completed'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">text</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ResponseTextConfig</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">format</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ResponseFormatText</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'text'</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">verbosity</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'medium'</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">top_logprobs</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">truncation</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'disabled'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">usage</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ResponseUsage</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">input_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">73</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">input_tokens_details</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">InputTokensDetails</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">cached_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">output_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">151</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">output_tokens_details</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">OutputTokensDetails</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">reasoning_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">total_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">224</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">user</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">store</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mResponse\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mid\u001b[0m=\u001b[32m'resp_07760e000eb25cdc0068c9d79c004481a3a09c1dfaefe39d87'\u001b[0m,\n",
       "    \u001b[33mcreated_at\u001b[0m=\u001b[1;36m1758058396\u001b[0m\u001b[1;36m.0\u001b[0m,\n",
       "    \u001b[33merror\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mincomplete_details\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33minstructions\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-5-nano-2025-08-07'\u001b[0m,\n",
       "    \u001b[33mobject\u001b[0m=\u001b[32m'response'\u001b[0m,\n",
       "    \u001b[33moutput\u001b[0m=\u001b[1m[\u001b[0m\n",
       "        \u001b[1;35mResponseReasoningItem\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mid\u001b[0m=\u001b[32m'rs_07760e000eb25cdc0068c9d79d790881a3a2054d2db49f34ae'\u001b[0m,\n",
       "            \u001b[33msummary\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "            \u001b[33mtype\u001b[0m=\u001b[32m'reasoning'\u001b[0m,\n",
       "            \u001b[33mcontent\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mencrypted_content\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mstatus\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mResponseFunctionToolCall\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33marguments\u001b[0m=\u001b[32m'\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\"name\":\"Colin\"\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m,\n",
       "            \u001b[33mcall_id\u001b[0m=\u001b[32m'call_y8ouIrJZrcKo0BCIP8UCSuVK'\u001b[0m,\n",
       "            \u001b[33mname\u001b[0m=\u001b[32m'cactify_name'\u001b[0m,\n",
       "            \u001b[33mtype\u001b[0m=\u001b[32m'function_call'\u001b[0m,\n",
       "            \u001b[33mid\u001b[0m=\u001b[32m'fc_07760e000eb25cdc0068c9d79e50ac81a3b4273b683a1e7e1d'\u001b[0m,\n",
       "            \u001b[33mstatus\u001b[0m=\u001b[32m'completed'\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[33mparallel_tool_calls\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
       "    \u001b[33mtemperature\u001b[0m=\u001b[1;36m1\u001b[0m\u001b[1;36m.0\u001b[0m,\n",
       "    \u001b[33mtool_choice\u001b[0m=\u001b[32m'auto'\u001b[0m,\n",
       "    \u001b[33mtools\u001b[0m=\u001b[1m[\u001b[0m\n",
       "        \u001b[1;35mFunctionTool\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mname\u001b[0m=\u001b[32m'cactify_name'\u001b[0m,\n",
       "            \u001b[33mparameters\u001b[0m=\u001b[1m{\u001b[0m\n",
       "                \u001b[32m'type'\u001b[0m: \u001b[32m'object'\u001b[0m,\n",
       "                \u001b[32m'properties'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'name'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'type'\u001b[0m: \u001b[32m'string'\u001b[0m, \u001b[32m'description'\u001b[0m: \u001b[32m'The name to be cactified.'\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                \u001b[32m'required'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m'name'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "                \u001b[32m'additionalProperties'\u001b[0m: \u001b[3;91mFalse\u001b[0m\n",
       "            \u001b[1m}\u001b[0m,\n",
       "            \u001b[33mstrict\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
       "            \u001b[33mtype\u001b[0m=\u001b[32m'function'\u001b[0m,\n",
       "            \u001b[33mdescription\u001b[0m=\u001b[32m'Transform a name into a fun, cactus-themed version.'\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[33mtop_p\u001b[0m=\u001b[1;36m1\u001b[0m\u001b[1;36m.0\u001b[0m,\n",
       "    \u001b[33mbackground\u001b[0m=\u001b[3;91mFalse\u001b[0m,\n",
       "    \u001b[33mconversation\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mmax_output_tokens\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mmax_tool_calls\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mprevious_response_id\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mprompt\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mprompt_cache_key\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mreasoning\u001b[0m=\u001b[1;35mReasoning\u001b[0m\u001b[1m(\u001b[0m\u001b[33meffort\u001b[0m=\u001b[32m'medium'\u001b[0m, \u001b[33mgenerate_summary\u001b[0m=\u001b[3;35mNone\u001b[0m, \u001b[33msummary\u001b[0m=\u001b[3;35mNone\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[33msafety_identifier\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mservice_tier\u001b[0m=\u001b[32m'default'\u001b[0m,\n",
       "    \u001b[33mstatus\u001b[0m=\u001b[32m'completed'\u001b[0m,\n",
       "    \u001b[33mtext\u001b[0m=\u001b[1;35mResponseTextConfig\u001b[0m\u001b[1m(\u001b[0m\u001b[33mformat\u001b[0m=\u001b[1;35mResponseFormatText\u001b[0m\u001b[1m(\u001b[0m\u001b[33mtype\u001b[0m=\u001b[32m'text'\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mverbosity\u001b[0m=\u001b[32m'medium'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[33mtop_logprobs\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
       "    \u001b[33mtruncation\u001b[0m=\u001b[32m'disabled'\u001b[0m,\n",
       "    \u001b[33musage\u001b[0m=\u001b[1;35mResponseUsage\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33minput_tokens\u001b[0m=\u001b[1;36m73\u001b[0m,\n",
       "        \u001b[33minput_tokens_details\u001b[0m=\u001b[1;35mInputTokensDetails\u001b[0m\u001b[1m(\u001b[0m\u001b[33mcached_tokens\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[33moutput_tokens\u001b[0m=\u001b[1;36m151\u001b[0m,\n",
       "        \u001b[33moutput_tokens_details\u001b[0m=\u001b[1;35mOutputTokensDetails\u001b[0m\u001b[1m(\u001b[0m\u001b[33mreasoning_tokens\u001b[0m=\u001b[1;36m128\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[33mtotal_tokens\u001b[0m=\u001b[1;36m224\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[33muser\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mstore\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "client = openai.Client()\n",
    "\n",
    "input_list = [{\"role\": \"user\", \"content\": \"What would my name, Colin, be if it were cactus-ified?\"}]\n",
    "tools = [cactify_name_schema]\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-5-nano\",\n",
    "    input=input_list,\n",
    "    tools=tools,\n",
    ")\n",
    "rich_print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596adf2e",
   "metadata": {},
   "source": [
    "Like the `curl` example, the response includes a function call with arguments. Let's extract and run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "011e0e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: Colinactus\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "def cactify_name(name: str) -> str:\n",
    "    \"\"\"\n",
    "    Makes a name more cactus-like by adding or replacing the end with 'ctus'.\n",
    "\n",
    "    Args:\n",
    "        name: The name to be cactified.\n",
    "\n",
    "    Returns:\n",
    "        The cactified version of the name.\n",
    "    \"\"\"\n",
    "\n",
    "    base_name = name\n",
    "\n",
    "    # Rule 1: If the name ends in 's' or 'x', remove it.\n",
    "    # Example: \"James\" -> \"Jame\", \"Alex\" -> \"Ale\"\n",
    "    if base_name.lower().endswith((\"s\", \"x\")):\n",
    "        base_name = base_name[:-1]\n",
    "\n",
    "    # Rule 2: If the name now ends in a vowel, remove it.\n",
    "    # Example: \"Jame\" -> \"Jam\", \"Mike\" -> \"Mik\", \"Anna\" -> \"Ann\"\n",
    "    if base_name and base_name.lower()[-1] in \"aeiou\":\n",
    "        base_name = base_name[:-1]\n",
    "\n",
    "    # Add the smoother suffix\n",
    "    return base_name + \"actus\"\n",
    "\n",
    "\n",
    "response_output = response.output\n",
    "# The model decided to call our function\n",
    "function_call = response.output[1]\n",
    "# Load the arguments provided by the model to call the function\n",
    "args = json.loads(function_call.arguments)\n",
    "result = cactify_name(**args)\n",
    "print(f\"Result: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174a6e25",
   "metadata": {},
   "source": [
    "Now that we have the output, we want to feed it back to the model to get a final response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b613c16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': 'What would my name, Colin, be if it were cactus-ified?'},\n",
       " ResponseReasoningItem(id='rs_07760e000eb25cdc0068c9d79d790881a3a2054d2db49f34ae', summary=[], type='reasoning', content=None, encrypted_content=None, status=None),\n",
       " ResponseFunctionToolCall(arguments='{\"name\":\"Colin\"}', call_id='call_y8ouIrJZrcKo0BCIP8UCSuVK', name='cactify_name', type='function_call', id='fc_07760e000eb25cdc0068c9d79e50ac81a3b4273b683a1e7e1d', status='completed'),\n",
       " {'type': 'function_call_output',\n",
       "  'call_id': 'call_y8ouIrJZrcKo0BCIP8UCSuVK',\n",
       "  'output': 'Colinactus'}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add the model's call to our function to the input list\n",
    "input_list += response_output\n",
    "# Append the function call output to the input list\n",
    "input_list.append(\n",
    "    {\"type\": \"function_call_output\", \"call_id\": function_call.call_id, \"output\": result}\n",
    ")\n",
    "input_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "447aad97",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.responses.create(\n",
    "    model=\"gpt-4o\",\n",
    "    instructions=\"Tell the user what their name would be if it were cactus-ified.\",\n",
    "    tools=tools,\n",
    "    input=input_list,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e2be1dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ResponseOutputText</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">annotations</span>=<span style=\"font-weight: bold\">[]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">text</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Your cactus-ified name would be \"Colinactus\"! ðŸŒµ'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'output_text'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">logprobs</span>=<span style=\"font-weight: bold\">[]</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mResponseOutputText\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mannotations\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[33mtext\u001b[0m=\u001b[32m'Your cactus-ified name would be \"Colinactus\"! ðŸŒµ'\u001b[0m,\n",
       "    \u001b[33mtype\u001b[0m=\u001b[32m'output_text'\u001b[0m,\n",
       "    \u001b[33mlogprobs\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rich_print(response.output[0].content[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c2f7a9",
   "metadata": {},
   "source": [
    "There we go! We've successfully used function calling with the Python SDK to cactify a name. It's a bit silly, but it shows how function calling can be used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4204d4",
   "metadata": {},
   "source": [
    "## Detecting function calls and saving history\n",
    "\n",
    "We manually called the function and fed the output back to the model. In a real application, you'd want to automate this process. You could write a loop that checks if the model's response includes a function call, executes the function, and then sends the result back to the model until you get a final text response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "df229f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_messages = []\n",
    "\n",
    "\n",
    "def prompt(user_input: str) -> str:\n",
    "    \"\"\"Prompt the model with the user input.\"\"\"\n",
    "\n",
    "    # Add the user input to the conversation history\n",
    "    all_messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "    # Prompt the model with the user input\n",
    "    response = client.responses.create(\n",
    "        model=\"gpt-5-nano\",\n",
    "        tools=tools,\n",
    "        input=all_messages,\n",
    "    )\n",
    "\n",
    "    for event in response.output:\n",
    "        all_messages.append(event)\n",
    "\n",
    "        # There's a request from the model to use a tool\n",
    "        if event.type == \"function_call\":\n",
    "            function_name = event.name\n",
    "            function_args = json.loads(event.arguments)\n",
    "\n",
    "            # Execute the function based on its name\n",
    "            if function_name == \"cactify_name\":\n",
    "                result = cactify_name(function_args[\"name\"])\n",
    "\n",
    "            # Add the function call output to the all_messages list\n",
    "            # Use the exact format expected by the API\n",
    "            all_messages.append(\n",
    "                {\n",
    "                    \"type\": \"function_call_output\",\n",
    "                    \"call_id\": event.call_id,\n",
    "                    \"output\": json.dumps(result),\n",
    "                }\n",
    "            )\n",
    "\n",
    "            # Now feed the function result back to the model\n",
    "            final_response = client.responses.create(\n",
    "                model=\"gpt-5-nano\",\n",
    "                instructions=\"Respond with the what the name would be if it were cactus-ified in a sentence.\",\n",
    "                tools=tools,\n",
    "                input=all_messages,\n",
    "            )\n",
    "\n",
    "            for final_event in final_response.output:\n",
    "                if final_event.type == \"message\":\n",
    "                    text = final_event.content[0].text\n",
    "                    all_messages.append({\"role\": \"assistant\", \"content\": text})\n",
    "                    return text\n",
    "\n",
    "        for event in response.output:\n",
    "            if event.type == \"message\":\n",
    "                text = event.content[0].text\n",
    "                all_messages.append({\"role\": \"assistant\", \"content\": text})\n",
    "                return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0e5d1fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colin would be Colinactus.\n"
     ]
    }
   ],
   "source": [
    "print(prompt(\"What would my name, Colin, be if it were cactus-ified?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0de325a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simon would be Simonactus.\n"
     ]
    }
   ],
   "source": [
    "print(prompt(\"What about Simon?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "3acdb916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You asked about Colin and Simon.\n"
     ]
    }
   ],
   "source": [
    "print(prompt(\"What names did I ask about\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247e2923",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
