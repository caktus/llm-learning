{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be57afbc-1ef0-4e96-8129-e8c9824d8830",
   "metadata": {},
   "source": [
    "# Agents\n",
    "\n",
    "AI agents are software systems that use AI to perform tasks on behalf of users. In this notebook, we'll experiment with creating and running AI agents using two different frameworks: OpenAI Agents and Pydantic AI.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Follow the README instructions to set up your Python environment.\n",
    "\n",
    "For the code examples that use local models, we'll be using Ollama's `llama3.2` model. If you haven't done so already, [install Ollama](https://ollama.com/download) on your computer and download the model with `ollama pull llama3.2`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea9ef96",
   "metadata": {},
   "source": [
    "## OpenAI Agents SDK\n",
    "\n",
    "The [OpenAI Agents SDK](https://github.com/openai/openai-agents-python/tree/main?tab=readme-ov-file#functions-example) is a tool that allows you to build agent-based workflows.\n",
    "\n",
    "This example shows how to build a simple agent that can call a function and return the result. Less code is required, and it automatically handles the conversation history using `last_response_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60634dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1: What's the weather in Tokyo?\n",
      "Response: The weather in Tokyo is currently partly cloudy with a temperature of 31°F. If you need more details or a forecast, let me know!\n",
      "\n",
      "==================================================\n",
      "\n",
      "Query 2: How about the weather in New York?\n",
      "Response: The weather in New York is currently partly cloudy with a temperature of 48°F. Let me know if you need more details or a forecast!\n",
      "\n",
      "==================================================\n",
      "\n",
      "Query 3: What cities did I ask about?\n",
      "Response: You asked about the weather in the following cities:\n",
      "\n",
      "1. Tokyo\n",
      "2. New York\n",
      "\n",
      "If you want to know about more cities or need updates, just let me know!\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "from agents import Agent, Runner, function_tool\n",
    "\n",
    "\n",
    "@function_tool\n",
    "def get_weather(city: str) -> dict:\n",
    "    \"\"\"Get the weather in a given city.\"\"\"\n",
    "    random_weather = random.choice([\"sunny\", \"cloudy\", \"rainy\", \"snowy\", \"partly cloudy\", \"stormy\"])\n",
    "    random_temp = random.randint(10, 100)\n",
    "\n",
    "    return {\n",
    "        \"conditions\": random_weather,\n",
    "        \"temperature\": random_temp,\n",
    "        \"city\": city,\n",
    "        \"units\": {\"temperature\": \"fahrenheit\"},\n",
    "    }\n",
    "\n",
    "\n",
    "# Create the agent with the weather tool\n",
    "agent = Agent(\n",
    "    name=\"Weather Agent\",\n",
    "    instructions=\"You are a helpful weather agent. When asked about weather, use the get_weather tool to provide accurate information.\",\n",
    "    tools=[get_weather],\n",
    ")\n",
    "\n",
    "\n",
    "async def main():\n",
    "    \"\"\"Main function to run the agent with conversation history.\"\"\"\n",
    "    # First query\n",
    "    result1 = await Runner.run(agent, input=\"What's the weather in Tokyo?\")\n",
    "    print(\"Query 1:\", \"What's the weather in Tokyo?\")\n",
    "    print(\"Response:\", result1.final_output)\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 50 + \"\\n\")\n",
    "\n",
    "    # Second query - pass the previous response ID to maintain conversation\n",
    "    result2 = await Runner.run(\n",
    "        agent,\n",
    "        input=\"How about the weather in New York?\",\n",
    "        previous_response_id=result1.last_response_id,\n",
    "    )\n",
    "    print(\"Query 2:\", \"How about the weather in New York?\")\n",
    "    print(\"Response:\", result2.final_output)\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 50 + \"\\n\")\n",
    "\n",
    "    # Third query - pass the previous response ID to maintain conversation\n",
    "    result3 = await Runner.run(\n",
    "        agent, input=\"What cities did I ask about?\", previous_response_id=result2.last_response_id\n",
    "    )\n",
    "    print(\"Query 3:\", \"What cities did I ask about?\")\n",
    "    print(\"Response:\", result3.final_output)\n",
    "\n",
    "\n",
    "await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cea92b0-c6e6-4a85-943f-d0ba5ed153b8",
   "metadata": {},
   "source": [
    "### Maintaining conversation history using a `Session`\n",
    "\n",
    "You can also use a `Session` object to maintain conversation history across multiple agent runs, instead of passing `previous_response_id` to `Runner.run()`. In the example below, we'll store the conversation history in an in-memory SQLite database, but you can pass a `db_path` argument to `SQLiteSession` for persistent storage. You can also implement your own session memory by creating a class that follows the `Session` protocol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9858d54b-3764-431e-bbe6-cc4a17a97242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1: What's the weather in Tokyo?\n",
      "Response: The weather in Tokyo is currently stormy, with a temperature of 45°F. If you need details about forecast or specific weather precautions, feel free to ask!\n",
      "\n",
      "==================================================\n",
      "\n",
      "Query 2: How about the weather in New York?\n",
      "Response: The weather in New York is partly cloudy with a temperature of 94°F. If you need more details or a forecast, just let me know!\n",
      "\n",
      "==================================================\n",
      "\n",
      "Query 3: What cities did I ask about?\n",
      "Response: You asked about the weather in two cities: Tokyo and New York. If you’d like information about other cities or more details about these, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "from agents import Agent, function_tool, SQLiteSession\n",
    "\n",
    "# Create a session instance\n",
    "session = SQLiteSession(session_id=\"my_session_id\")\n",
    "\n",
    "\n",
    "@function_tool\n",
    "def get_weather(city: str) -> dict:\n",
    "    \"\"\"Get the weather in a given city.\"\"\"\n",
    "    random_weather = random.choice([\"sunny\", \"cloudy\", \"rainy\", \"snowy\", \"partly cloudy\", \"stormy\"])\n",
    "    random_temp = random.randint(10, 100)\n",
    "\n",
    "    return {\n",
    "        \"conditions\": random_weather,\n",
    "        \"temperature\": random_temp,\n",
    "        \"city\": city,\n",
    "        \"units\": {\"temperature\": \"fahrenheit\"},\n",
    "    }\n",
    "\n",
    "\n",
    "# Create the agent with the weather tool\n",
    "agent = Agent(\n",
    "    name=\"Weather Agent\",\n",
    "    instructions=\"You are a helpful weather agent. When asked about weather, use the get_weather tool to provide accurate information.\",\n",
    "    tools=[get_weather],\n",
    ")\n",
    "\n",
    "\n",
    "async def main():\n",
    "    \"\"\"Main function to run the agent with conversation history.\"\"\"\n",
    "    # First query\n",
    "    result1 = await Runner.run(agent, input=\"What's the weather in Tokyo?\", session=session)\n",
    "    print(\"Query 1:\", \"What's the weather in Tokyo?\")\n",
    "    print(\"Response:\", result1.final_output)\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 50 + \"\\n\")\n",
    "\n",
    "    # Second query\n",
    "    result2 = await Runner.run(\n",
    "        agent,\n",
    "        input=\"How about the weather in New York?\",\n",
    "        session=session,\n",
    "    )\n",
    "    print(\"Query 2:\", \"How about the weather in New York?\")\n",
    "    print(\"Response:\", result2.final_output)\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 50 + \"\\n\")\n",
    "\n",
    "    # Third query\n",
    "    result3 = await Runner.run(agent, input=\"What cities did I ask about?\", session=session)\n",
    "    print(\"Query 3:\", \"What cities did I ask about?\")\n",
    "    print(\"Response:\", result3.final_output)\n",
    "\n",
    "\n",
    "await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0350024f-233d-43a5-99a7-7ed4044437d4",
   "metadata": {},
   "source": [
    "### Using local models\n",
    "\n",
    "The SDK's integration with [LiteLLM](https://docs.litellm.ai/) allows us to use models from many other providers, including local Ollama models. We will use the same code as before, but provide an Ollama model to the `Agent` constructor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb4069a4-047d-46df-944e-4addb53d9a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1: What's the weather in Tokyo?\n",
      "Response: The current weather in Tokyo is sunny with a temperature of 60°F (15°C).\n",
      "\n",
      "==================================================\n",
      "\n",
      "Query 2: How about the weather in New York?\n",
      "Response: The current weather in New York is cloudy with a temperature of 93°F (34°C).\n",
      "\n",
      "==================================================\n",
      "\n",
      "Query 3: What cities did I ask about?\n",
      "Response: You asked about the weather in Tokyo and New York.\n"
     ]
    }
   ],
   "source": [
    "from agents import Agent, function_tool, SQLiteSession, set_tracing_disabled\n",
    "from agents.extensions.models.litellm_provider import LitellmProvider\n",
    "\n",
    "# Disable tracing. By default, the SDK will send information about agent runs to\n",
    "# OpenAI. We don't necessarily want this when using local models.\n",
    "set_tracing_disabled(True)\n",
    "\n",
    "# Create a session instance\n",
    "session = SQLiteSession(session_id=\"my_session_id\")\n",
    "\n",
    "\n",
    "@function_tool\n",
    "def get_weather(city: str) -> dict:\n",
    "    \"\"\"Get the weather in a given city.\"\"\"\n",
    "    random_weather = random.choice([\"sunny\", \"cloudy\", \"rainy\", \"snowy\", \"partly cloudy\", \"stormy\"])\n",
    "    random_temp = random.randint(10, 100)\n",
    "\n",
    "    return {\n",
    "        \"conditions\": random_weather,\n",
    "        \"temperature\": random_temp,\n",
    "        \"city\": city,\n",
    "        \"units\": {\"temperature\": \"fahrenheit\"},\n",
    "    }\n",
    "\n",
    "\n",
    "# Create the agent with the weather tool\n",
    "agent = Agent(\n",
    "    name=\"Weather Agent\",\n",
    "    instructions=\"You are a helpful weather agent. When asked about weather, use the get_weather tool to provide accurate information.\",\n",
    "    tools=[get_weather],\n",
    "    model=LitellmProvider().get_model(\"ollama_chat/llama3.2\"),\n",
    ")\n",
    "\n",
    "\n",
    "async def main():\n",
    "    \"\"\"Main function to run the agent with conversation history.\"\"\"\n",
    "    # First query\n",
    "    result1 = await Runner.run(agent, input=\"What's the weather in Tokyo?\", session=session)\n",
    "    print(\"Query 1:\", \"What's the weather in Tokyo?\")\n",
    "    print(\"Response:\", result1.final_output)\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 50 + \"\\n\")\n",
    "\n",
    "    # Second query\n",
    "    result2 = await Runner.run(agent, input=\"How about the weather in New York?\", session=session)\n",
    "    print(\"Query 2:\", \"How about the weather in New York?\")\n",
    "    print(\"Response:\", result2.final_output)\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 50 + \"\\n\")\n",
    "\n",
    "    # Third query\n",
    "    result3 = await Runner.run(agent, input=\"What cities did I ask about?\", session=session)\n",
    "    print(\"Query 3:\", \"What cities did I ask about?\")\n",
    "    print(\"Response:\", result3.final_output)\n",
    "\n",
    "\n",
    "await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a136621",
   "metadata": {},
   "source": [
    "## Pydantic AI Agents\n",
    "\n",
    "[Pydantic AI](https://ai.pydantic.dev/) is another framework for creating and running AI agents. It also supports many different model providers, and its API is kinda similar to the OpenAI Agents SDK.\n",
    "\n",
    "Let's use it to recreate the same weather agent we created before, using OpenAI's `gpt-5-nano` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dda19764-91ec-428d-98bf-07db4ed8cbea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1: What's the weather in Tokyo?\n",
      "Response: In Tokyo, it's partly cloudy with a temperature of 73°F (about 23°C).\n",
      "\n",
      "==================================================\n",
      "\n",
      "Query 2: How about the weather in New York?\n",
      "Response: In New York, it's snowy with a temperature of 19°F (-7°C). Stay warm out there.\n",
      "\n",
      "==================================================\n",
      "\n",
      "Query 3: What cities did I ask about?\n",
      "Response: You asked about Tokyo and New York.\n"
     ]
    }
   ],
   "source": [
    "from pydantic_ai import Agent\n",
    "\n",
    "\n",
    "def get_weather(city: str) -> dict:\n",
    "    \"\"\"Get the weather in a given city.\"\"\"\n",
    "    random_weather = random.choice([\"sunny\", \"cloudy\", \"rainy\", \"snowy\", \"partly cloudy\", \"stormy\"])\n",
    "    random_temp = random.randint(10, 100)\n",
    "\n",
    "    return {\n",
    "        \"conditions\": random_weather,\n",
    "        \"temperature\": random_temp,\n",
    "        \"city\": city,\n",
    "        \"units\": {\"temperature\": \"fahrenheit\"},\n",
    "    }\n",
    "\n",
    "\n",
    "# Create the agent with the weather tool\n",
    "agent = Agent(\n",
    "    name=\"Weather Agent\",\n",
    "    instructions=\"You are a helpful weather agent. When asked about weather, use the get_weather tool to provide accurate information.\",\n",
    "    tools=[get_weather],\n",
    "    model=\"openai:gpt-5-nano\",\n",
    ")\n",
    "\n",
    "\n",
    "async def main():\n",
    "    \"\"\"Main function to run the agent with conversation history.\"\"\"\n",
    "    # First query\n",
    "    result1 = await agent.run(\"What's the weather in Tokyo?\")\n",
    "    print(\"Query 1:\", \"What's the weather in Tokyo?\")\n",
    "    print(\"Response:\", result1.output)\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 50 + \"\\n\")\n",
    "\n",
    "    # Second query - pass the message history so far to maintain conversation\n",
    "    result2 = await agent.run(\n",
    "        \"How about the weather in New York?\", message_history=result1.all_messages()\n",
    "    )\n",
    "    print(\"Query 2:\", \"How about the weather in New York?\")\n",
    "    print(\"Response:\", result2.output)\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 50 + \"\\n\")\n",
    "\n",
    "    # Third query - pass the message history so far to maintain conversation\n",
    "    result3 = await agent.run(\n",
    "        \"What cities did I ask about?\", message_history=result2.all_messages()\n",
    "    )\n",
    "    print(\"Query 3:\", \"What cities did I ask about?\")\n",
    "    print(\"Response:\", result3.output)\n",
    "\n",
    "\n",
    "await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af49ca18",
   "metadata": {},
   "source": [
    "### Using local models\n",
    "\n",
    "We can also create our agent using an Ollama model. We'll only change the `model` argument in the `Agent` constructor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc6d91ac-7736-4fff-aa72-c04622e3a822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1: What's the weather in Tokyo?\n",
      "Response: There is currently snowy weather in Tokyo with a temperature of 22°F.\n",
      "\n",
      "==================================================\n",
      "\n",
      "Query 2: How about the weather in New York?\n",
      "Response: There is currently snowy weather in New York with a temperature of 10°F.\n",
      "\n",
      "==================================================\n",
      "\n",
      "Query 3: What cities did I ask about?\n",
      "Response: You asked about the weather in Tokyo and New York.\n"
     ]
    }
   ],
   "source": [
    "from pydantic_ai import Agent\n",
    "from pydantic_ai.models.openai import OpenAIChatModel\n",
    "from pydantic_ai.providers.ollama import OllamaProvider\n",
    "\n",
    "\n",
    "def get_weather(city: str) -> dict:\n",
    "    \"\"\"Get the weather in a given city.\"\"\"\n",
    "    random_weather = random.choice([\"sunny\", \"cloudy\", \"rainy\", \"snowy\", \"partly cloudy\", \"stormy\"])\n",
    "    random_temp = random.randint(10, 100)\n",
    "\n",
    "    return {\n",
    "        \"conditions\": random_weather,\n",
    "        \"temperature\": random_temp,\n",
    "        \"city\": city,\n",
    "        \"units\": {\"temperature\": \"fahrenheit\"},\n",
    "    }\n",
    "\n",
    "\n",
    "# Create the agent with the weather tool\n",
    "# We could also set the `model` to OpenAIChatModel(model_name=\"llama3.2\", provider=\"ollama\")\n",
    "# if we have a OLLAMA_BASE_URL environment variable (e.g. OLLAMA_BASE_URL=http://localhost:11434/v1)\n",
    "agent = Agent(\n",
    "    name=\"Weather Agent\",\n",
    "    instructions=\"You are a helpful weather agent. When asked about weather, use the get_weather tool to provide accurate information.\",\n",
    "    tools=[get_weather],\n",
    "    model=OpenAIChatModel(\n",
    "        model_name=\"llama3.2\", provider=OllamaProvider(base_url=\"http://localhost:11434/v1\")\n",
    "    ),\n",
    ")\n",
    "\n",
    "\n",
    "async def main():\n",
    "    \"\"\"Main function to run the agent with conversation history.\"\"\"\n",
    "    # First query\n",
    "    result1 = await agent.run(\"What's the weather in Tokyo?\")\n",
    "    print(\"Query 1:\", \"What's the weather in Tokyo?\")\n",
    "    print(\"Response:\", result1.output)\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 50 + \"\\n\")\n",
    "\n",
    "    # Second query - pass the message history so far to maintain conversation\n",
    "    result2 = await agent.run(\n",
    "        \"How about the weather in New York?\", message_history=result1.all_messages()\n",
    "    )\n",
    "    print(\"Query 2:\", \"How about the weather in New York?\")\n",
    "    print(\"Response:\", result2.output)\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 50 + \"\\n\")\n",
    "\n",
    "    # Third query - pass the message history so far to maintain conversation\n",
    "    result3 = await agent.run(\n",
    "        \"What cities did I ask about?\", message_history=result2.all_messages()\n",
    "    )\n",
    "    print(\"Query 3:\", \"What cities did I ask about?\")\n",
    "    print(\"Response:\", result3.output)\n",
    "\n",
    "\n",
    "await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f143b63-fc96-408c-8cdf-c802f618241e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
